# Assistant IA CAN 2025 - Template de configuration

# ============= API Keys =============
# Clé API Groq (GRATUIT - recommandé)
# Obtenez votre clé sur: https://console.groq.com/keys
GROQ_API_KEY=your_groq_api_key_here

# Clé API OpenAI (optionnel - payant)
OPENAI_API_KEY=your_openai_api_key_here

# Alternative: Clé pour d'autres providers LLM
# ANTHROPIC_API_KEY=your_anthropic_key
# HUGGINGFACE_API_KEY=your_huggingface_key

# ============= Configuration LLM =============
# Provider LLM (groq ou openai)
LLM_PROVIDER=groq

# Modèle à utiliser
# Groq: llama-3.3-70b-versatile, llama-3.1-8b-instant, mixtral-8x7b-32768, gemma2-9b-it
# OpenAI: gpt-3.5-turbo, gpt-4, etc.
LLM_MODEL=llama-3.3-70b-versatile

# Température (0.0 = déterministe, 1.0 = créatif)
LLM_TEMPERATURE=0.7

# Nombre max de tokens par réponse
LLM_MAX_TOKENS=1000

# ============= Configuration RAG =============
# Nom de la collection ChromaDB
COLLECTION_NAME=can2025_knowledge

# Répertoire de persistance
PERSIST_DIRECTORY=./vectorstore/index

# Nombre de documents à récupérer par recherche
N_RESULTS=3

# Modèle d'embeddings
EMBEDDING_MODEL=all-MiniLM-L6-v2

# ============= Configuration API =============
# Port de l'API FastAPI
API_PORT=8000

# Host de l'API
API_HOST=0.0.0.0

# Mode debug
DEBUG=True

# ============= Configuration Frontend =============
# URL de l'API backend
API_URL=http://localhost:8000

# Port Streamlit
STREAMLIT_PORT=8501
